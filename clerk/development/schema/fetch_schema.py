from pathlib import Path
from typing import Any, List, Optional, Dict
from enum import Enum
from pydantic import BaseModel, Field

from clerk.client import Clerk


class VariableTypes(str, Enum):
    STRING = "string"
    NUMBER = "number"
    DATE = "date"
    BOOLEAN = "boolean"
    DATETIME = "datetime"
    TIME = "time"
    OBJECT = "object"
    ENUM = "enum"


class VariableData(BaseModel):
    id: str
    name: str
    display_name: str
    tags: List[str] = []
    units: Optional[str] = None
    description: Optional[str] = None
    is_array: bool
    parent_id: Optional[str] = None
    type: VariableTypes
    position_index: int
    additional_properties: Optional[bool] = None
    default: Any | None = None
    enum_options: List[str] = Field(default_factory=list)


def fetch_schema(project_id: str) -> List[VariableData]:
    """
    Fetch schema from Clerk backend for a given project.

    Args:
        project_id: The project ID to fetch schema for

    Returns:
        List of VariableData objects
    """
    client = Clerk(base_url="http://localhost:8001/CbZMlsdwbc")
    endpoint = "/schema"
    params = {"project_id": project_id}
    res = client.get_request(endpoint=endpoint, params=params)
    return [VariableData.model_validate(item) for item in res.data]


def _python_type_from_variable(var: VariableData, nested_models: Dict[str, str]) -> str:
    """Convert VariableData type to Python type string"""
    type_map = {
        VariableTypes.STRING: "str",
        VariableTypes.NUMBER: "float",
        VariableTypes.DATE: "date",
        VariableTypes.DATETIME: "datetime",
        VariableTypes.TIME: "time",
        VariableTypes.BOOLEAN: "bool",
        VariableTypes.ENUM: "str",  # Will be refined with Literal if enum_options exist
    }

    if var.type == VariableTypes.OBJECT:
        # Use the nested model class name
        base_type = nested_models.get(var.id, "Dict[str, Any]")
    elif var.type == VariableTypes.ENUM and var.enum_options:
        # Create Literal type for enum
        options = ", ".join([f'"{opt}"' for opt in var.enum_options])
        base_type = f"Literal[{options}]"
    else:
        base_type = type_map.get(var.type, "Any")

    # Handle arrays
    if var.is_array:
        return f"List[{base_type}]"

    return base_type


def generate_models_from_schema(
    variables: List[VariableData], output_file: Optional[Path] = None
) -> str:
    """
    Generate Pydantic BaseModel classes from schema variables.
    
    Args:
        variables: List of VariableData objects
        output_file: Optional path to write the generated code
        
    Returns:
        Generated Python code as string
    """
    # Group variables by parent_id
    root_vars: List[VariableData] = []
    nested_vars: Dict[str, List[VariableData]] = {}

    for var in sorted(variables, key=lambda v: v.position_index):
        if var.parent_id is None:
            root_vars.append(var)
        else:
            if var.parent_id not in nested_vars:
                nested_vars[var.parent_id] = []
            nested_vars[var.parent_id].append(var)

    # Map variable IDs to their generated class names using name field
    nested_models: Dict[str, str] = {}
    var_id_to_data: Dict[str, VariableData] = {var.id: var for var in variables}

    for parent_id in nested_vars.keys():
        parent_var = var_id_to_data.get(parent_id)
        if parent_var and parent_var.name:
            # Use name field and convert snake_case to PascalCase
            class_name = "".join(
                word.capitalize() for word in parent_var.name.split("_")
            )
        else:
            # Fallback to parent_id
            class_name = "".join(word.capitalize() for word in parent_id.split("_"))
        nested_models[parent_id] = class_name

    code_lines: List[str] = []

    # Autogenerated code comment
    code_lines.append("# Autogenerated by the fetch_schema tool - do not edit manually.\n")

    # Generate imports
    imports = [
        "from typing import Any, List, Optional, Dict",
        "from datetime import date, datetime, time",
        "from pydantic import BaseModel, Field",
    ]

    # Check if we need Literal
    has_enums = any(var.type == VariableTypes.ENUM and var.enum_options for var in variables)
    if has_enums:
        imports[0] = "from typing import Any, List, Optional, Dict, Literal"

    code_lines.extend(imports)
    code_lines.append("")

    # Generate nested models first (bottom-up)
    generated_classes = set()

    def generate_class(var_id: str, vars_list: List[VariableData], class_name: str):
        if class_name in generated_classes:
            return

        # First generate any nested children
        for var in vars_list:
            if var.type == VariableTypes.OBJECT and var.id in nested_vars:
                child_class_name = nested_models[var.id]
                generate_class(var.id, nested_vars[var.id], child_class_name)

        # Generate this class
        code_lines.append(f"class {class_name}(BaseModel):")

        if not vars_list:
            code_lines.append("    pass")
        else:
            for var in sorted(vars_list, key=lambda v: v.position_index):
                field_name = var.name
                python_type = _python_type_from_variable(var, nested_models)

                # Build field definition
                field_parts = []
                if var.description:
                    # Escape double quotes in description
                    escaped_desc = var.description.replace('"', '\\"')
                    field_parts.append(f'description="{escaped_desc}"')
                if var.default is not None:
                    field_parts.append(f"default={repr(var.default)}")

                if field_parts:
                    field_def = f"Field({', '.join(field_parts)})"
                    code_lines.append(f"    {field_name}: {python_type} = {field_def}")
                else:
                    code_lines.append(f"    {field_name}: {python_type}")

        code_lines.append("")
        generated_classes.add(class_name)

    # Generate all nested models
    for var_id, vars_list in nested_vars.items():
        class_name = nested_models[var_id]
        generate_class(var_id, vars_list, class_name)

    # Generate root model
    code_lines.append("class StructuredData(BaseModel):")
    if not root_vars:
        code_lines.append("    pass")
    else:
        for var in sorted(root_vars, key=lambda v: v.position_index):
            field_name = var.name
            python_type = _python_type_from_variable(var, nested_models)

            # Build field definition
            field_parts = []
            if var.description:
                # Escape double quotes in description
                escaped_desc = var.description.replace('"', '\\"')
                field_parts.append(f'description="{escaped_desc}"')
            if var.default is not None:
                field_parts.append(f"default={repr(var.default)}")

            if field_parts:
                field_def = f"Field({', '.join(field_parts)})"
                code_lines.append(f"    {field_name}: {python_type} = {field_def}")
            else:
                code_lines.append(f"    {field_name}: {python_type}")

    generated_code = "\n".join(code_lines)

    # Write to file if specified
    if output_file:
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(generated_code)

    return generated_code


def main_with_args(project_id: str, project_root: Path | None = None):
    """Main logic that can be called from CLI or programmatically"""
    print(f"Fetching schema for project: {project_id}")
    variables = fetch_schema(project_id)
    print(f"Found {len(variables)} variables")

    # Always save to schema.py in project root
    if project_root is None:
        project_root = Path.cwd()
    output_file = project_root / "schema.py"

    generate_models_from_schema(variables, output_file)

    print(f"âœ… Schema generated and written to: {output_file}")
